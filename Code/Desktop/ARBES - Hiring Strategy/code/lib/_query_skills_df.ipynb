{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_scores(df):\n",
    "    \"\"\"\n",
    "    Calculate scores for priority columns while preserving other columns.\n",
    "    Adds a total column that sums only the priority-based scores.\n",
    "    \n",
    "    Rules:\n",
    "    - 'Critical' prefix & True value = 20\n",
    "    - 'Required' prefix & True value = 10\n",
    "    - 'Preferred' prefix & True value = 7\n",
    "    - 'Optional' prefix & True value = 3\n",
    "    - All other columns preserved as-is\n",
    "    - 'total_priority_score' column added with sum of priority scores\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with boolean columns\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: New DataFrame with scores and total\n",
    "    \"\"\"\n",
    "    # Define priority prefixes\n",
    "    priority_prefixes = ['Critical', 'Required', 'Preferred', 'Optional']\n",
    "    \n",
    "    # Create a copy of the input DataFrame\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Track which columns are priority columns for summing later\n",
    "    priority_columns = []\n",
    "    \n",
    "    # Process each column in the source DataFrame\n",
    "    for col in df.columns:\n",
    "        # Check if column starts with any of our priority prefixes\n",
    "        if any(col.startswith(prefix) for prefix in priority_prefixes):\n",
    "            new_values = pd.Series(0, index=df.index)\n",
    "            \n",
    "            if col.startswith('Critical'):\n",
    "                new_values[df[col]] = 20\n",
    "            elif col.startswith('Required'):\n",
    "                new_values[df[col]] = 10\n",
    "            elif col.startswith('Preferred'):\n",
    "                new_values[df[col]] = 7\n",
    "            elif col.startswith('Optional'):\n",
    "                new_values[df[col]] = 3\n",
    "                \n",
    "            result_df[col] = new_values\n",
    "            priority_columns.append(col)\n",
    "    \n",
    "    # Add total column that sums only priority-based scores\n",
    "    result_df['total_priority_score'] = result_df[priority_columns].sum(axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_skills_matrix(skills_dict, distance_threshold=.8):\n",
    "    \"\"\"\n",
    "    Create a DataFrame showing which entities possess which skills based on ChromaDB similarity search.\n",
    "    Skills are categorized by priority level and reflected in column names.\n",
    "    \n",
    "    Args:\n",
    "        skills_dict (dict): Dictionary of skills categorized by priority level\n",
    "                           Format: {\n",
    "                               'Critical': ['skill1', 'skill2'],\n",
    "                               'Required': ['skill3', 'skill4'],\n",
    "                               'Preferred': ['skill5', 'skill6'],\n",
    "                               'Optional': ['skill7', 'skill8']\n",
    "                           }\n",
    "        distance_threshold (float): Maximum distance to consider a skill match (default: .8)\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Matrix of entities and their skills with priority level prefixes\n",
    "    \"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    # Initialize ChromaDB client with persistence\n",
    "    client = chromadb.PersistentClient(path=\"../entity_skills_db\")\n",
    "\n",
    "    # Initialize the OpenAI embedding function\n",
    "    embedding_function = OpenAIEmbeddingFunction(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model_name=\"text-embedding-3-large\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Get existing collection\n",
    "        collection = client.get_collection(\n",
    "            name=\"entity_skills\",\n",
    "            embedding_function=embedding_function\n",
    "        )\n",
    "        \n",
    "        # Dictionary to store all results\n",
    "        all_entity_skills = {}\n",
    "        \n",
    "        # Create a mapping of all skills to their priority levels\n",
    "        skill_priority_map = {\n",
    "            skill: priority\n",
    "            for priority, skills in skills_dict.items()\n",
    "            for skill in skills\n",
    "        }\n",
    "        \n",
    "        # Get all skills across all priority levels\n",
    "        all_skills = [skill for skills in skills_dict.values() for skill in skills]\n",
    "        \n",
    "        # Query each skill\n",
    "        for skill in all_skills:\n",
    "            results = collection.query(\n",
    "                query_texts=[skill],\n",
    "                n_results=1000,  # Large number to get all potential matches\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            # Process results for this skill\n",
    "            for entity_metadata, distance in zip(\n",
    "                results['metadatas'][0],\n",
    "                results['distances'][0]\n",
    "            ):\n",
    "                entity_id = entity_metadata.get('entity_name')\n",
    "                \n",
    "                # Initialize entity in dictionary if not present\n",
    "                if entity_id not in all_entity_skills:\n",
    "                    # Initialize with prefixed column names\n",
    "                    all_entity_skills[entity_id] = {\n",
    "                        f\"{priority}_{skill}\": False\n",
    "                        for priority, skills in skills_dict.items()\n",
    "                        for skill in skills\n",
    "                    }\n",
    "                \n",
    "                # Mark skill as True if distance is below threshold\n",
    "                if distance < distance_threshold:\n",
    "                    priority = skill_priority_map[skill]\n",
    "                    all_entity_skills[entity_id][f\"{priority}_{skill}\"] = True\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame.from_dict(all_entity_skills, orient='index')\n",
    "        \n",
    "        # Reset index and rename it to entity_id\n",
    "        df.index.name = 'entity_id'\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing collection: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dictionary of skills to query\n",
    "    skills_to_query = {\n",
    "        'Critical': ['Python', 'Data Analysis'],\n",
    "        'Required': ['Amazon Web Services', 'Machine Learning', 'PyTorch'],\n",
    "        'Preferred': ['Docker', 'SQL', 'SQL Server', 'PostgreSQL'],\n",
    "        'Optional': ['Kubernetes', 'React', 'GCP'],\n",
    "    }\n",
    "    \n",
    "    # Create the skills matrix\n",
    "    skills_df = create_skills_matrix(skills_to_query)\n",
    "\n",
    "    \n",
    "    # Display some summary statistics\n",
    "    print(\"\\nSkill Distribution:\")\n",
    "    for priority, skills in skills_to_query.items():\n",
    "        print(f\"\\n{priority} Skills:\")\n",
    "        for skill in skills:\n",
    "            column_name = f\"{priority}_{skill}\"\n",
    "            count = skills_df[column_name].sum()\n",
    "            total = len(skills_df)\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"{skill}: {count} entities ({percentage:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df = calculate_scores(skills_df)\n",
    "scored_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_skills_matrix_with_distances(skills_dict):\n",
    "    \"\"\"\n",
    "    Create a DataFrame showing the best (smallest) distance scores between entities and skills \n",
    "    based on ChromaDB similarity search.\n",
    "    \n",
    "    Args:\n",
    "        skills_dict (dict): Dictionary of skills categorized by priority level\n",
    "                           Format: {\n",
    "                               'Critical': ['skill1', 'skill2'],\n",
    "                               'Required': ['skill3', 'skill4'],\n",
    "                               'Preferred': ['skill5', 'skill6'],\n",
    "                               'Optional': ['skill7', 'skill8']\n",
    "                           }\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Matrix of entities and their best skill distances with priority level prefixes\n",
    "    \"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    # Initialize ChromaDB client with persistence\n",
    "    client = chromadb.PersistentClient(path=\"../entity_skills_db\")\n",
    "\n",
    "    # Initialize the OpenAI embedding function\n",
    "    embedding_function = OpenAIEmbeddingFunction(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model_name=\"text-embedding-3-large\"\n",
    "    )\n",
    "\n",
    "    # Get existing collection\n",
    "    collection = client.get_collection(\n",
    "        name=\"entity_skills\",\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    all_entity_skills = {}\n",
    "    \n",
    "    # Create a mapping of all skills to their priority levels\n",
    "    skill_priority_map = {\n",
    "        skill: priority\n",
    "        for priority, skills in skills_dict.items()\n",
    "        for skill in skills\n",
    "    }\n",
    "    \n",
    "    # Get all skills across all priority levels\n",
    "    all_skills = [skill for skills in skills_dict.values() for skill in skills]\n",
    "    \n",
    "    # Query each skill\n",
    "    for skill in all_skills:\n",
    "        results = collection.query(\n",
    "            query_texts=[skill],\n",
    "            n_results=1000,  # Large number to get all potential matches\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        # Process results for this skill\n",
    "        for entity_metadata, distance in zip(\n",
    "            results['metadatas'][0],\n",
    "            results['distances'][0]\n",
    "        ):\n",
    "            entity_id = entity_metadata.get('entity_name')\n",
    "            \n",
    "            # Initialize dictionary for new entity if needed\n",
    "            if entity_id not in all_entity_skills:\n",
    "                all_entity_skills[entity_id] = {}\n",
    "            \n",
    "            # Get the column name\n",
    "            priority = skill_priority_map[skill]\n",
    "            column_name = f\"{priority}_{skill}\"\n",
    "            \n",
    "            # Update the distance if it's either not set yet or if this one is smaller\n",
    "            current_distance = all_entity_skills[entity_id].get(column_name, None)\n",
    "            if current_distance is None or distance < current_distance:\n",
    "                all_entity_skills[entity_id][column_name] = round(distance, 2)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame.from_dict(all_entity_skills, orient='index')\n",
    "    \n",
    "    # Reset index and rename it to entity_id\n",
    "    df.index.name = 'entity_id'\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dictionary of skills to query\n",
    "    skills_to_query = {\n",
    "        'Critical': ['Python Programming', 'Data Analysis'],\n",
    "        'Required': ['Amazon Web Services', 'Machine Learning', 'PyTorch'],\n",
    "        'Preferred': ['Docker', 'SQL', 'SQL Server', 'PostgreSQL'],\n",
    "        'Optional': ['Kubernetes', 'React', 'GCP', 'Google Cloud', 'Google Cloud Platform'],\n",
    "    }\n",
    "    \n",
    "    # Create the skills matrix with distances\n",
    "    skills_distances_df = create_skills_matrix_with_distances(skills_to_query)\n",
    "    \n",
    "    # Display some summary statistics\n",
    "    print(\"\\nSkill Distance Statistics:\")\n",
    "    for priority, skills in skills_to_query.items():\n",
    "        print(f\"\\n{priority} Skills:\")\n",
    "        for skill in skills:\n",
    "            column_name = f\"{priority}_{skill}\"\n",
    "            mean_distance = skills_distances_df[column_name].mean()\n",
    "            close_matches = (skills_distances_df[column_name] < 0.8).sum()\n",
    "            total = len(skills_distances_df)\n",
    "            percentage = (close_matches / total) * 100\n",
    "            print(f\"{skill}:\")\n",
    "            print(f\"  Mean distance: {mean_distance:.2f}\")\n",
    "            print(f\"  Close matches (<0.8): {close_matches} entities ({percentage:.1f}%)\")\n",
    "            \n",
    "    # Optional: Display the top 5 closest matches for each skill\n",
    "    print(\"\\nTop 5 Closest Matches by Skill:\")\n",
    "    for priority, skills in skills_to_query.items():\n",
    "        print(f\"\\n{priority} Skills:\")\n",
    "        for skill in skills:\n",
    "            column_name = f\"{priority}_{skill}\"\n",
    "            print(f\"\\n{skill}:\")\n",
    "            top_5 = skills_distances_df.nsmallest(5, column_name)[['entity_id', column_name]]\n",
    "            print(top_5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_distances_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
