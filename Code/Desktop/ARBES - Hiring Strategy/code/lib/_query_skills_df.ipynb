{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 1000 is greater than number of elements in index 9, updating n_results = 9\n",
      "Number of requested results 1000 is greater than number of elements in index 9, updating n_results = 9\n",
      "Number of requested results 1000 is greater than number of elements in index 9, updating n_results = 9\n",
      "Number of requested results 1000 is greater than number of elements in index 9, updating n_results = 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skills Matrix:\n",
      "      entity_id  Python Programming  Data Analysis    AWS  Machine Learning\n",
      "0    Alice Chen                True          False   True             False\n",
      "1  Bob Martinez                True          False   True             False\n",
      "2    Carol Wong                True          False  False              True\n",
      "\n",
      "Skill Distribution:\n",
      "Python Programming: 3 entities (100.0%)\n",
      "Data Analysis: 0 entities (0.0%)\n",
      "AWS: 2 entities (66.7%)\n",
      "Machine Learning: 1 entities (33.3%)\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_skills_matrix(skill_list, distance_threshold=1.0):\n",
    "    \"\"\"\n",
    "    Create a DataFrame showing which entities possess which skills based on ChromaDB similarity search.\n",
    "    \n",
    "    Args:\n",
    "        skill_list (list): List of skills to query\n",
    "        distance_threshold (float): Maximum distance to consider a skill match (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Matrix of entities and their skills\n",
    "    \"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    # Initialize ChromaDB client with persistence\n",
    "    client = chromadb.PersistentClient(path=\"../entity_skills_db\")\n",
    "\n",
    "    # Initialize the OpenAI embedding function\n",
    "    embedding_function = OpenAIEmbeddingFunction(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model_name=\"text-embedding-3-large\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Get existing collection\n",
    "        collection = client.get_collection(\n",
    "            name=\"entity_skills\",\n",
    "            embedding_function=embedding_function\n",
    "        )\n",
    "        \n",
    "        # Dictionary to store all results\n",
    "        all_entity_skills = {}\n",
    "        \n",
    "        # Query each skill\n",
    "        for skill in skill_list:\n",
    "            results = collection.query(\n",
    "                query_texts=[skill],\n",
    "                n_results=1000,  # Large number to get all potential matches\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            # Process results for this skill\n",
    "            for entity_metadata, distance in zip(\n",
    "                results['metadatas'][0],\n",
    "                results['distances'][0]\n",
    "            ):\n",
    "                entity_id = entity_metadata.get('entity_name')\n",
    "                \n",
    "                # Initialize entity in dictionary if not present\n",
    "                if entity_id not in all_entity_skills:\n",
    "                    all_entity_skills[entity_id] = {skill: False for skill in skill_list}\n",
    "                \n",
    "                # Mark skill as True if distance is below threshold\n",
    "                if distance < distance_threshold:\n",
    "                    all_entity_skills[entity_id][skill] = True\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame.from_dict(all_entity_skills, orient='index')\n",
    "        \n",
    "        # Reset index and rename it to entity_id\n",
    "        df.index.name = 'entity_id'\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing collection: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example list of skills to query\n",
    "    skills_to_query = [\n",
    "        \"Python Programming\",\n",
    "        \"Data Analysis\",\n",
    "        \"AWS\",\n",
    "        \"Machine Learning\"\n",
    "    ]\n",
    "    \n",
    "    # Create the skills matrix\n",
    "    skills_df = create_skills_matrix(skills_to_query)\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSkills Matrix:\")\n",
    "    # print(skills_df.head())\n",
    "    \n",
    "    # Display some summary statistics\n",
    "    print(\"\\nSkill Distribution:\")\n",
    "    for skill in skills_to_query:\n",
    "        count = skills_df[skill].sum()\n",
    "        total = len(skills_df)\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"{skill}: {count} entities ({percentage:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
