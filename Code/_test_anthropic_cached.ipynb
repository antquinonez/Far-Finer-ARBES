{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:45:40,878 - __main__ - INFO - Starting Anthropic Cached command-line interface\n",
      "2024-11-17 20:45:40,880 - lib.AI.FFAnthropicCached - INFO - Initializing FFAnthropicCached\n",
      "2024-11-17 20:45:40,881 - lib.AI.FFAnthropicCached - INFO - Initializing Anthropic client\n",
      "2024-11-17 20:45:40,904 - __main__ - INFO - FFAnthropicCached initialized successfully\n",
      "2024-11-17 20:45:40,905 - __main__ - INFO - AI initialized. Type 'exit' to quit.\n",
      "2024-11-17 20:45:47,745 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 20:45:47,754 - lib.AI.FFAnthropicCached - INFO - Response generated successfully\n",
      "2024-11-17 20:45:47,756 - __main__ - INFO - Response generated and displayed to user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: As an AI language model, I don't have feelings or personal experiences, but I'm functioning well and ready to assist you with any questions or information you need. How can I help you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:45:57,980 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 20:45:57,984 - lib.AI.FFAnthropicCached - INFO - Response generated successfully\n",
      "2024-11-17 20:45:57,985 - __main__ - INFO - Response generated and displayed to user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm glad to hear that. Since you don't have a specific question or task in mind, please feel free to ask about any topic you're curious about or if you need help with something later. I'm here to assist with a wide range of subjects, from general knowledge to more specific inquiries. Don't hesitate to reach out whenever you need information or have a question!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:46:09,872 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 20:46:09,877 - lib.AI.FFAnthropicCached - INFO - Response generated successfully\n",
      "2024-11-17 20:46:09,879 - __main__ - INFO - Response generated and displayed to user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: You're welcome! I'm happy to help anytime. If you ever need assistance in the future, feel free to ask. Have a great day!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:46:17,002 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-11-17 20:46:17,006 - lib.AI.FFAnthropicCached - INFO - Response generated successfully\n",
      "2024-11-17 20:46:17,007 - __main__ - INFO - Response generated and displayed to user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Goodbye! Take care, and feel free to return anytime if you need help or information. Have a great rest of your day!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:46:19,549 - __main__ - INFO - User requested to exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n",
      "HISTORY: {'how are you?': [{'sequence_number': 1, 'model': 'claude-3-5-sonnet-20240620', 'timestamp': 1731905147.7544432, 'prompt_name': 'how are you?', 'prompt': 'how are you?', 'response': \"As an AI language model, I don't have feelings or personal experiences, but I'm functioning well and ready to assist you with any questions or information you need. How can I help you today?\", 'datetime': '2024-11-17T20:45:47.754443'}], 'great. no problem': [{'sequence_number': 2, 'model': 'claude-3-5-sonnet-20240620', 'timestamp': 1731905157.9842358, 'prompt_name': 'great. no problem', 'prompt': 'great. no problem', 'response': \"I'm glad to hear that. Since you don't have a specific question or task in mind, please feel free to ask about any topic you're curious about or if you need help with something later. I'm here to assist with a wide range of subjects, from general knowledge to more specific inquiries. Don't hesitate to reach out whenever you need information or have a question!\", 'datetime': '2024-11-17T20:45:57.984236'}], 'thanks for the helpo': [{'sequence_number': 3, 'model': 'claude-3-5-sonnet-20240620', 'timestamp': 1731905169.8770185, 'prompt_name': 'thanks for the helpo', 'prompt': 'thanks for the helpo', 'response': \"You're welcome! I'm happy to help anytime. If you ever need assistance in the future, feel free to ask. Have a great day!\", 'datetime': '2024-11-17T20:46:09.877018'}], 'cya later': [{'sequence_number': 4, 'model': 'claude-3-5-sonnet-20240620', 'timestamp': 1731905177.0059676, 'prompt_name': 'cya later', 'prompt': 'cya later', 'response': 'Goodbye! Take care, and feel free to return anytime if you need help or information. Have a great rest of your day!', 'datetime': '2024-11-17T20:46:17.005968'}]}\n",
      "stats: {'how are you?': 1, 'great. no problem': 1, 'thanks for the helpo': 1, 'cya later': 1}\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2024 Antonio Quinonez\n",
    "# Licensed under the MIT License. See LICENSE in the project root for license information.\n",
    "\n",
    "from lib.AI.FFAnthropicCached import FFAnthropicCached\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Starting Anthropic Cached command-line interface\")\n",
    "\n",
    "    config = {\n",
    "        'max_tokens': 2000,\n",
    "        'temperature': 0.7,\n",
    "        'system_instructions': 'Tell the truth.'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Create an instance of the class\n",
    "        ai = FFAnthropicCached(config, model=\"claude-3-5-sonnet-20240620\")\n",
    "        logger.info(\"FFAnthropicCached initialized successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to initialize FFAnthropicCached: %s\", str(e))\n",
    "        return\n",
    "\n",
    "    logger.info(\"AI initialized. Type 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input    \n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        # Check if the user wants to exit\n",
    "        if user_input.lower() == 'exit':\n",
    "            logger.info(\"User requested to exit\")\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Generate a response\n",
    "            logger.debug(\"Generating response for user input: %s\", user_input)\n",
    "            response = ai.generate_response(user_input, prompt_name=user_input)\n",
    "            print(\"Assistant:\", response)\n",
    "            logger.info(\"Response generated and displayed to user\")\n",
    "        except Exception as e:\n",
    "            logger.error(\"An error occurred while generating response: %s\", str(e))\n",
    "\n",
    "            history = ai.get_prompt_dict()\n",
    "            print(f\"HISTORY: {history}\")\n",
    "\n",
    "            stats = ai.get_prompt_name_usage_stats()\n",
    "            print(f\"stats: {stats}\")\n",
    "\n",
    "    history = ai.get_prompt_dict()\n",
    "    print(f\"HISTORY: {history}\")\n",
    "\n",
    "    stats = ai.get_prompt_name_usage_stats()\n",
    "    print(f\"stats: {stats}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
